# Amazon EC2 Backup Strategy

# Rationale

It is crucial that all data stored on various instances of our infrastructure is backup'd regularly so that one can recover in case of data loss or hardware failure. Each data store must be represented in the backup and it must be possible to recover all data at any time. This also holds for configurations that define how applications and instances run. 

With respect to the available admin resources for this project the aim of a backup solution is not find a way between perfection and chaos that keeps the amount of work to a minimum level without compromising the aim. One building block to achieve this is to make the setup of a backup for a data store (or whole instance) as easy as possible. That is being made possible by providing all administrators a simple backup script that can be configured in 5 minutes. Another building block is to define that backups are not accurate to the minute or even hour but are executed once every day. That means that you can loose at most 23 hours of data if hardware fails 23 hours after the last backup. Considering the non linear increasing amount of additional work required to build a solution that would give minute accuracy the current timeframe is deemed ok for the data we're dealing with.

The technology behind our backup solution is based on a customized use of GIT repositories that are located on a central backup server. Each client creates an index of all files to backup and then pushes them to that server. That approach guarantees that we have a full history for each file including diffs for plaintext and that space consumption is kept to a minimum by storing only the differences. In addition to that our tool will split and pack files to save space.

The central backup server is configured with enough space to hold a large amount of backup data. To be able to also recover data in case of a failure or data loss all repositories are sync'd to a S3 bucket. The following image depicts the current structure. On the left hand you see the instances involved. For each of these instances you see the directories or data stores being backup'd. In addition to that you can see the time each of the backups runs. On the right hand you see the structure of the backup server with separate git repositories for each instance.

<img src="/wiki/images/amazon/EC2BackupStrategy.jpg" width="100%" height="100%"/>

# BUP: Technology

BUP is the tool that is being used to create the backups. If you look at it in detail then this is just a very sophisticated wrapper around GIT. Unlike git, it writes packfiles directly (instead of having a separate garbage collection / repacking stage) so it's fast even with gratuitously huge amounts of data. bup's improved index formats also allow you to track far more filenames than git (millions) and keep track of far more objects (hundreds or thousands of gigabytes). As with git you have three stages when starting a backup.

- First you need to initialize the repository (comparable to `git init`). This is also needed when using a remote repository. In that case the local repository is used to hold the index of files and to determine wether files have changed. The initialization is executed by invoking `bup [-d /path/to/repo] init`. In most cases you can just omit the directory - bup will then set it to $HOME/.bup.
- Second you need to tell bup to create or update the index (comparable to `git add`). That operation will list all files and add them to the index. That index contains information about changes to the tree structure. At this stage you can specify wether to ignore certain files (--exclude and --exclude-rx). An index command could look like this: `bup index /etc`.
- Third all indexed files need to be saved (comparable to `git commit`). That process can either store files locally (comparable to `git commit`) or push them to a remote repository (`git commit && git push`).

The last stage involves some magic because bup does not expose the notion of branches or HEAD to the user. In most cases one will save files by specifying the name of a backup (`bup save -n <name>`). Internally this will create or update a branch that matches the name given. More importantly this operation will remove all files not matching the index just created. Assuming that you save /etc by specifying mybackup as the name of the backup. Then you save /var/log by using the same name. That will lead to /etc not being included into the commit on that branch because it does not match path /var/log.